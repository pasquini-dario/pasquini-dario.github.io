<!DOCTYPE HTML>

<html>
	<head>
		<title>Dario Pasquini personal page</title>
		<link rel="icon" type="image/x-icon" href="favicon.ico">
		<meta name="google-site-verification" content="4ufx4V1x6lKJzuGnX-YoqdGxtML7p5mhmRjg6EPlgvA" />
		<meta name="description" content="Dario's personal page">
		<meta http-equiv="content-type" content="text/html;charset=UTF-8">
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="main.css" />
	</head>
	<body class="is-preload">

		<!-- Header -->
	
			<header id="header">
				<div class="inner">
					<a href="#" class="image avatar" id="avatar"><img src="me.png" alt="" /></a>
					<p id="myname"> Dario Pasquini</p>
					<a id="side_a" href="mailto:chime.infant_0g@icloud.com"> chime.infant_0g@icloud.com</a>
					<br>
					<br>
					<a id="side_a" href="https://github.com/pasquini-dario/">üê± GitHub</a>
					<br>
					<a id="side_a" href="https://scholar.google.com/citations?user=L38xA_8AAAAJ&hl">üéì Scholar</a>
					<br>
					<a id="side_a" href="../CV.pdf">üóíÔ∏è Ext. C.V.</a>
				</div>
			</header>
	
	
		<!-- Main -->
			<div id="main">


				<h2>Status:</h2>
				<ul id="no-bullets">
			<li>
				Researcher at RSAC Labs--<i>"Semi-honest-model-unbeliever"</i>  seeking security and privacy measures that transcend trust, ideal assumptions, and heuristic security definitions <i id="lighter"> (but, in reality, I spend most of my time either breaking ML models or building ML models to break stuff)</i>.
			</li>
			<li>
				Working on:
					<ul id="workingon">
				
						<li> LLMs & agentic stuff sec.<i id="lighter"> (yes, I know..)</i></li>
						<li> Privacy in Collaborative Machine Learning <i id="lighter"> (I play for the good team; the red one..)</i></li>
				
						<li>Password Security ‚ù§Ô∏è</li>
					</ul>
				</li>
			</ul>
			<hr>


		<h2>Preprints:</h2>
		<ul>
	
			<li> <u>Dario Pasquini</u>, Evgenios M. Kornaropoulos, Giuseppe Ateniese. <br> <a href="https://arxiv.org/pdf/2410.20911"> Hacking Back the AI-Hacker: Prompt Injection as a Defense Against LLM-driven Cyberattacks</a> 
				<br>
			<b>Media coverage: </b><a id=media href="https://www.darkreading.com/cybersecurity-operations/deceptive-framework-defense-mislead-attacking-ai">Dark Reading</a>, </b><a id=media href="https://www.schneier.com/blog/archives/2024/11/prompt-injection-defenses-against-llm-cyberattacks.html">Schneier</a>, </b><a id=media href="https://www.thestack.technology/mantis-framework-poisons-traps-hackers-ai-agents-in-a-tarpit/">The Stack</a>

			</li>

		</ul>

		<h2>Projects I wish I had the time to maintain:</h2>

<ul style="list-style: none; display: flex; flex-direction: column; align-items: flex-start; padding: 0;">
    <li style="display: flex; align-items: center; margin-bottom: 10px; padding: 1px 0;">
        <img src="logo_mantis.png" alt="Mantis Logo" style="width: 60px; height: auto; margin-right: 10px;">
        <a href="https://github.com/pasquini-dario/project_mantis" style="font-size: 16px; color: #333; text-decoration: none;">
            <span style="font-weight: bold;">Project Mantis:</span> Defending from LLM-driven cyberattacks using prompt injection
        </a>
    </li>
    <li style="display: flex; align-items: center; margin-bottom: 10px; padding: 1px 0;">
        <img src="logo_llmap.png" alt="Mantis Logo" style="width: 60px; height: auto; margin-right: 10px;">
        <a href="https://github.com/pasquini-dario/LLMmap" style="font-size: 16px; color: #333; text-decoration: none;">
            <span style="font-weight: bold;">LLMmap:</span> like nmap but for LLMs...
        </a>
    </li>
    <li style="display: flex; align-items: center; margin-bottom: 10px; padding: 1px 0;">
        <img src="logo_nex.jpeg" alt="Mantis Logo" style="width: 60px; height: auto; margin-right: 10px;">
        <a href="https://github.com/pasquini-dario/LLM_NeuralExec" style="font-size: 16px; color: #333; text-decoration: none;">
            <span style="font-weight: bold;">NeuralExec:</span> Toolset to generate highly effective (optimization-based) prompt injections 
        </a>
    </li>
</ul>
	
			<h2>Works I like to talk about:</h2>
			<ul>

		    		<li id="mainpub"> <b>[USENIX Sec'25] </b> <u>Dario Pasquini</u>, Evgenios M. Kornaropoulos, Giuseppe Ateniese.  <br>  <a href="https://arxiv.org/pdf/2407.15847"> LLMmap: Fingerprinting For Large Language Models</a>  </li>
				
	            		<li id="mainpub"> <b>[ACM AISec 24] </b> <u>Dario Pasquini</u>, Martin Strohmeier, Carmela Troncoso. <br> <a href="https://arxiv.org/abs/2403.03792"> Neural Exec: Learning (and Learning from) Execution Triggers for Prompt Injection Attacks</a>  </li>
	            
				<li id="mainpub">
					 <b>[IEEE S&P'24] </b>  -- <u>Dario Pasquini</u>, Danilo Francati, Giuseppe Ateniese, Evgenios M. Kornaropoulos. <br> <a href="https://eprint.iacr.org/2023/1848">Breach Extraction Attacks: Exposing and Addressing the Leakage in Second Generation Compromised Credential Checking Services</a> 
					 <br>
					
				 </li>
				<li  id="mainpub"> <b>[IEEE S&P'24] </b> -- <u>Dario Pasquini</u>,  Giuseppe Ateniese, Carmela Troncoso. <br> <a href="https://arxiv.org/abs/2301.07628">Universal Neural-Cracking-Machines: Self-Configurable Password Models from Auxiliary Data</a>


				</li>
				<li  id="mainpub"> <b>[IEEE S&P'23]</b> -- <u>Dario Pasquini</u>, Mathilde Raynal, Carmela Troncoso. <br>	<a href="https://arxiv.org/pdf/2205.08443">On the (In)security of Peer-to-Peer Decentralized Machine Learning</a>
	
				</li>
				<li  id="mainpub"> <b>[ACM CCS'22]</b>  	-- <u>Dario Pasquini</u>, Danilo Francati, Giuseppe Ateniese. <br>	<a href="https://arxiv.org/pdf/2111.07380">Eluding Secure Aggregation in Federated Learning via Model Inconsistency</a>
	
				</li>
	
				<li  id="mainpub">
					<b>[ACM CCS'21]</b> -- <u>Dario Pasquini</u>, Giuseppe Ateniese, Massimo Bernaschi. <br> 	<a href="https://arxiv.org/abs/2012.02670">Unleashing the Tiger: Inference Attacks on Split Learning</a>
	
				</li>
				<li  id="mainpub">
					<b>[USENIX Sec'21]</b> -- <u>Dario Pasquini</u>, Marco Cianfriglia, Giuseppe Ateniese, Massimo Bernaschi.<br>	<a href="https://arxiv.org/abs/2010.12269">Reducing Bias in Modeling Real-world Password Strength via Deep Learning and Dynamic Dictionaries</a>
	
				</li>
				<li  id="mainpub">
					<b>[IEEE S&P'21]</b> -- <u>Dario Pasquini</u>, Ankit Gangwal, Giuseppe Ateniese, Massimo Bernaschi, Mauro Conti. <br> <a href="https://arxiv.org/abs/1910.04232">Improving Password Guessing via Representation Learning</a>
	
	<!-- 			<li id="bib">
					<b>[ESORICS 20]</b> - <b>Dario Pasquini</b>, Giuseppe Ateniese, Massimo Bernaschi.
					<a href="https://arxiv.org/abs/2004.07179">Interpretable probabilistic password strength meters via deep learning</a>.
				</li> -->
			</ul>

<hr>

<h5> Talks <i id="lighter">(the ones I remembered to put here)</i>: </h5>
<ul >
	   <li>
		<a href="https://drive.google.com/file/d/1xv9YyYow7fGGV0_g8KZnglfCDIAomPqe/view?usp=sharing">"Hacking-back the AI-Hacker (Mantis)"</i></a> [RSAC conference 2025]
	</li>

    <li>
		<a href="https://pasquini-dario.github.io/nn.pdf">"Neural Exec: Learning Execution Triggers for Prompt Injection Attacks"</i></a> [Swiss AI Sec. Network, Sapienza University]
	</li>
	<li>
		<a href="https://pasquini-dario.github.io/PPCML.pdf">"Privacy Preserving Collaborative Machine Learning?"</a> </i> [CNR Italy, Inria Rennes, Monash University, Roma3 University, JPMorgan AlgoCRYPT Center of Excellence]
	</li>
	<li>
		<a href="https://drive.google.com/file/d/1MWtoJpqIsVgEhI15jQjWzuEX5YqJT4P4/view">"Password Alchemy with Universal Neural-Cracking-Machines: Transmuting email addresses into Password Models"</i></a> [PasswordsCon'23, Roma3 University]
	</li>

</ul>
<hr>

  <h5> Program Committees: </h5>
	<ul id="no-bullets">
		<li>
			 <a href="https://sp2026.ieee-security.org/index.html">IEEE S&P 2026</a>
			 </li>

			<li>
				<a href="https://www.sigsac.org/ccs/CCS2023/">ACM CCS 2023/2025</a>
			</li>


			 <li>
			 <a href="https://www.usenix.org/conference/usenixsecurity23">USENIX Sec 2023/2025</a>
			 </li>

			 <li>
			 <a href="https://satml.org">IEEE SaTML 2024/2025</a>
			 </li>

			 <li>
			 <a href="https://petsymposium.org/cfp25.php">PETS 2025</a>
			 </li>
			 
		</li>
	</ul>
<hr>

	<h5> Things I don't work on, but I'd love to üîÆ: </h5>
	<ul id="no-bullets">
		<li><i id="high">Hardware sec, Cryptanalysis.</i></li>
	</ul>



	<!--
			<h3>Media coverage:</h3>
			<ul>
				<li>
					<a href="https://edtechmagazine.com/higher/article/2020/10/3-ways-ai-can-help-users-avoid-weak-passwords">EdTech: 3 Ways That AI Can Help Users Avoid Weak Passwords</a>
				</li>
				<li>
					<a href="https://www.stevens.edu/news/new-tool-helps-public-test-their-own-passwords--and-bolster-security"> Stevens News: New Tool Helps Public Test Their Own Passwords ‚Äî and Bolster Security </a>
				</li>
			</ul>

 -->

	</div>
	
	</body>


</html>
